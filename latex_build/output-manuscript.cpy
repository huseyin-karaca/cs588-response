\clipboard {text:1.3a}{Graph Convolutional Network (GCN)}
\clipboard {text:4.3a}{Graph Convolutional Network (GCN)}
\clipboard {text:4.3b}{bug repositories}
\clipboard {text:1.3b}{for example, 20\% of reports in Eclipse and 30\% in Firefox were marked as duplicate}
\clipboard {text:2.6}{for example, 20\% of reports in Eclipse and 30\% in Firefox were marked as duplicate}
\clipboard {text:3.7}{for example, 20\% of reports in Eclipse and 30\% in Firefox were marked as duplicate}
\clipboard {text:4.1a}{The core challenge in Duplicate Bug Report Detection (DBRD) is to automatically identify whether two bug reports describe the same underlying software defect. Formally, given a bug repository $\mathcal {R} = \{r_1, r_2, ..., r_n\}$ where each report $r_i$ contains textual fields (title, description) and metadata (timestamp, reporter, component), the task is to learn a function $f: \mathcal {R} \times \mathcal {R} \rightarrow \{0, 1\}$ that predicts whether a pair of reports $(r_i, r_j)$ are duplicates. This is inherently difficult due to lexical variations, incomplete descriptions, domain-specific terminology, and reporting style differences across users.}
\clipboard {text:4.1b}{In realistic software development environments, the availability of labeled data is severely limited. While a repository may contain tens of thousands of bug reports, only a small fraction (typically less than 5\%) have confirmed duplicate relationships manually identified by developers or triagers. The remaining reports remain unlabeled, representing a vast untapped resource that conventional supervised learning approaches cannot effectively utilize.}
\clipboard {text:4.1c}{Transformer-based language models such as BERT, RoBERTa, and their domain-adapted variants have demonstrated strong performance in semantic text matching tasks. However, these models face fundamental limitations in the DBRD setting. Consider a concrete scenario: a repository contains 20,000 bug reports with only 500 confirmed duplicate pairs (1,000 labeled reports). A pairwise BERT-based classifier would be trained on these 500 positive pairs plus an equal number of sampled negative pairs, effectively utilizing only 1,000 reports while completely disregarding the remaining 19,000 unlabeled reports.}
\clipboard {text:4.1d}{The quadratic growth of potential pairs exacerbates this problem. For $n$ bug reports, there exist $\binom {n}{2} = \frac {n(n-1)}{2}$ possible pairs. For 20,000 reports, this yields approximately 200 million pairs, making exhaustive pairwise training computationally infeasible. Existing approaches employ negative sampling strategies, but these methods lack a principled mechanism to propagate semantic information across the unlabeled corpus. Moreover, they are limited by the explicit supervision paradigm: without a label for a pair $(r_i, r_j)$, the model receives no training signal involving those reports together.}
\clipboard {text:4.1e}{To illustrate the practical limitation, consider two bug reports from an Eclipse repository: \textit {Report A (ID 12345):} "NullPointerException in editor when opening XML file with invalid schema reference" \textit {Report B (ID 67890):} "NPE thrown during XML editor initialization with broken schema link." These reports clearly describe the same bug using different terminology ("NullPointerException" vs. "NPE", "opening" vs. "initialization", "invalid reference" vs. "broken link"). A well-trained transformer model with sufficient labeled examples from the XML editor domain would likely identify this pair as duplicates through semantic similarity. However, suppose the training set contains only 100 labeled duplicate pairs, none of which involve the XML editor component or schema-related issues. The transformer model, trained exclusively on these 100 pairs, would lack the domain-specific context to recognize the semantic equivalence between Reports A and B. Meanwhile, the repository contains 500 other unlabeled reports related to XML editing, including variations of similar terminology and error patterns. A purely supervised LLM-based approach cannot leverage these 500 reports during training, as they lack explicit duplicate labels.}
\clipboard {text:4.1h}{Graph neural networks provide a natural solution to overcome these limitations. Unlike pairwise supervised learning, GNNs operate on relational neighborhoods and propagate information through message passing across connected nodes without requiring explicit labels for every connection. This enables us to construct a unified graph representation where all available bug reports---both labeled and unlabeled---participate in the learning process.}
\clipboard {text:4.1i}{In our framework, edges are formed based on label-independent semantic similarity (e.g., cosine similarity of title embeddings), enabling efficient graph construction without additional manual annotations. The transformer component operates on a restricted but feasible subset of report pairs during training: positive pairs from known duplicates and negative pairs sampled from different groups. The representations learned from these labeled pairs are embedded as graph node features, and the GNN propagates this information across the entire graph through neighborhood aggregation.}
\clipboard {text:4.1j}{Returning to the XML editor example: even though Reports A and B may not appear in the training set, if they are connected through intermediate nodes (other XML-related reports) in the graph, the GNN can propagate relevant semantic information to them. Although direct supervision is applied only to nodes in labeled pairs, the graph structure allows information flow to unpaired and unlabeled nodes, enabling the model to benefit from the full corpus. This design decouples pairwise supervision from global data utilization, making it suitable for realistic, label-scarce duplicate bug report detection scenarios.}
\clipboard {text:4.3d}{where $N$ denotes the total number of bug reports in the repository}
\clipboard {text:1.3c}{i.e., the negative pair sampling}
\clipboard {text:4.3e}{i.e., the negative pair sampling}
\clipboard {text:4.3f}{\textit {Graph Construction},}
\clipboard {text:4.3g}{early stopping based on validation performance; specifically, training is stopped if validation loss does not improve for 3 consecutive epochs (patience=3)}
\clipboard {text:1.4}{All source code and the full reproducibility package, including all necessary data files and scripts, can be found in the \href {https://github.com/huseyin-karaca/graph-enhanced-dbd.git}{huseyin-karaca/graph-enhanced-dbd GitHub repository \faLink }.}
\clipboard {text:2.4}{It is important to emphasize that the goal of this work is not merely to achieve marginal numerical improvements over existing baselines, but rather to demonstrate that a graph-enhanced semi-supervised framework can reach competitive performance while explicitly leveraging unlabeled data during training. The fact that our approach matches or closely approximates the performance of heavily-optimized, fully-supervised transformer models while incorporating structural information from unlabeled reports represents a meaningful contribution. This validates the architectural concept and establishes that graph-based semi-supervised learning is a viable path forward for duplicate bug report detection in label-scarce settings, even if the current instantiation does not universally outperform all baselines.}
\clipboard {text:3.8}{It is important to emphasize that the goal of this work is not merely to achieve marginal numerical improvements over existing baselines, but rather to demonstrate that a graph-enhanced semi-supervised framework can reach competitive performance while explicitly leveraging unlabeled data during training. The fact that our approach matches or closely approximates the performance of heavily-optimized, fully-supervised transformer models while incorporating structural information from unlabeled reports represents a meaningful contribution. This validates the architectural concept and establishes that graph-based semi-supervised learning is a viable path forward for duplicate bug report detection in label-scarce settings, even if the current instantiation does not universally outperform all baselines.}
\clipboard {text:1.1}{The detailed convergence plots are shown in Fig. \ref {fig:convergence_eclipse} and \ref {fig:convergence_thunderbird} for Eclipse and Thunderbird datasets, respectively.}
\clipboard {text:4.11}{The detailed convergence plots are shown in Fig. \ref {fig:convergence_eclipse} and \ref {fig:convergence_thunderbird} for Eclipse and Thunderbird datasets, respectively.}
\clipboard {text:2.1}{An important remark is that the current experiments use full training datasets for only graph construction, not for transformer training. A key motivation for graph-based semi-supervised learning is its potential effectiveness under label-scarce conditions. Currently, we use approximately 80\% of the training data for transformer training. Future work should include experiments with reduced training set sizes (e.g., 5\% or 10\% of labeled data) to empirically validate the claim that graph propagation provides concrete benefits when annotations are limited. Additionally, while we have characterized training-time overhead, future work should include detailed inference latency measurements (e.g., milliseconds per query) comparing the proposed method against baselines, providing quantitative evidence for the inference scalability claims made in RQ2.}
\clipboard {text:2.5}{An important remark is that the current experiments use full training datasets for only graph construction, not for transformer training. A key motivation for graph-based semi-supervised learning is its potential effectiveness under label-scarce conditions. Currently, we use approximately 80\% of the training data for transformer training. Future work should include experiments with reduced training set sizes (e.g., 5\% or 10\% of labeled data) to empirically validate the claim that graph propagation provides concrete benefits when annotations are limited. Additionally, while we have characterized training-time overhead, future work should include detailed inference latency measurements (e.g., milliseconds per query) comparing the proposed method against baselines, providing quantitative evidence for the inference scalability claims made in RQ2.}
\clipboard {text:2.2a}{An important remark is that the current experiments use full training datasets for only graph construction, not for transformer training. A key motivation for graph-based semi-supervised learning is its potential effectiveness under label-scarce conditions. Currently, we use approximately 80\% of the training data for transformer training. Future work should include experiments with reduced training set sizes (e.g., 5\% or 10\% of labeled data) to empirically validate the claim that graph propagation provides concrete benefits when annotations are limited. Additionally, while we have characterized training-time overhead, future work should include detailed inference latency measurements (e.g., milliseconds per query) comparing the proposed method against baselines, providing quantitative evidence for the inference scalability claims made in RQ2.}
\clipboard {text:1.2}{Several hyperparameters in our framework were fixed based on preliminary experiments without exhaustive ablation studies. The PCA dimensionality (d=10), projection dimension (D=128), fusion weight ($\lambda $), margin (m) in the loss function, and number of training epochs all warrant systematic sensitivity analysis. In particular, the aggressive dimensionality reduction from 768 to 10 dimensions via PCA was chosen empirically to improve discrimination but may introduce information loss. Future work should explore different values of d (e.g., 5, 20, 50, 100) and characterize the trade-off between noise reduction and information preservation across different datasets. Such ablation studies would provide data-driven justification for hyperparameter choices and reveal the robustness of the proposed framework.}
\clipboard {text:2.3}{Several hyperparameters in our framework were fixed based on preliminary experiments without exhaustive ablation studies. The PCA dimensionality (d=10), projection dimension (D=128), fusion weight ($\lambda $), margin (m) in the loss function, and number of training epochs all warrant systematic sensitivity analysis. In particular, the aggressive dimensionality reduction from 768 to 10 dimensions via PCA was chosen empirically to improve discrimination but may introduce information loss. Future work should explore different values of d (e.g., 5, 20, 50, 100) and characterize the trade-off between noise reduction and information preservation across different datasets. Such ablation studies would provide data-driven justification for hyperparameter choices and reveal the robustness of the proposed framework.}
\clipboard {text:2.7}{Several hyperparameters in our framework were fixed based on preliminary experiments without exhaustive ablation studies. The PCA dimensionality (d=10), projection dimension (D=128), fusion weight ($\lambda $), margin (m) in the loss function, and number of training epochs all warrant systematic sensitivity analysis. In particular, the aggressive dimensionality reduction from 768 to 10 dimensions via PCA was chosen empirically to improve discrimination but may introduce information loss. Future work should explore different values of d (e.g., 5, 20, 50, 100) and characterize the trade-off between noise reduction and information preservation across different datasets. Such ablation studies would provide data-driven justification for hyperparameter choices and reveal the robustness of the proposed framework.}
\clipboard {text:3.2}{Several hyperparameters in our framework were fixed based on preliminary experiments without exhaustive ablation studies. The PCA dimensionality (d=10), projection dimension (D=128), fusion weight ($\lambda $), margin (m) in the loss function, and number of training epochs all warrant systematic sensitivity analysis. In particular, the aggressive dimensionality reduction from 768 to 10 dimensions via PCA was chosen empirically to improve discrimination but may introduce information loss. Future work should explore different values of d (e.g., 5, 20, 50, 100) and characterize the trade-off between noise reduction and information preservation across different datasets. Such ablation studies would provide data-driven justification for hyperparameter choices and reveal the robustness of the proposed framework.}
\clipboard {text:3.3}{The current negative sampling strategy combines anchor-based pairing with random sampling across duplicate groups. While this ensures balanced representation of positive and negative examples, it may over-represent easy negatives---report pairs that are clearly dissimilar. Hard negative mining, which focuses on difficult non-duplicates (reports that appear similar but describe different bugs), could improve the model's ability to learn fine-grained decision boundaries. Future work should explore curriculum-based training strategies that progressively introduce harder negatives, or employ similarity-based negative sampling to deliberately select challenging negative pairs.}
\clipboard {text:3.1}{In this work, graph edges are constructed based solely on semantic similarity of bug report titles. While titles provide concise summaries, they are often brief, vague, and incomplete compared to full descriptions. Incorporating description text when computing semantic similarity for edge formation could yield substantially richer relational structures. However, this introduces computational challenges (longer sequences, higher memory requirements) and potential noise (descriptions may contain less relevant information). Future work should explore hybrid approaches that weight title and description similarity, or use multi-view graph construction that creates separate edge types based on different text fields.}
\clipboard {text:4.2}{In this work, graph edges are constructed based solely on semantic similarity of bug report titles. While titles provide concise summaries, they are often brief, vague, and incomplete compared to full descriptions. Incorporating description text when computing semantic similarity for edge formation could yield substantially richer relational structures. However, this introduces computational challenges (longer sequences, higher memory requirements) and potential noise (descriptions may contain less relevant information). Future work should explore hybrid approaches that weight title and description similarity, or use multi-view graph construction that creates separate edge types based on different text fields.}
\clipboard {text:3.5}{Our evaluation is limited to two benchmark datasets from large, open-source projects (Eclipse and Thunderbird). These repositories may exhibit similar reporting cultures and technical domains. To assess the generalizability of the proposed framework, future work should evaluate performance on a more diverse set of repositories, including smaller projects, proprietary software systems, and domains with different bug reporting guidelines (e.g., mobile applications, embedded systems, web services). Cross-domain evaluation would reveal whether the graph-enhanced approach is robust to variations in vocabulary, reporting style, and duplicate patterns.}
\clipboard {text:3.4}{For extremely large bug repositories (e.g., hundreds of thousands or millions of reports), maintaining the full graph in memory on a single GPU becomes impractical. Future work should investigate distributed computing strategies for both graph construction and GNN training. Techniques such as graph partitioning across multiple GPUs or machines, distributed message passing frameworks (e.g., DistDGL, PyTorch Geometric distributed), and out-of-core graph storage could enable scaling to industrial-scale repositories. Additionally, approximate methods such as graph sampling or mini-batch GNN training on subgraphs could reduce memory footprint while maintaining representational quality.}
\clipboard {text:3.9}{For extremely large bug repositories (e.g., hundreds of thousands or millions of reports), maintaining the full graph in memory on a single GPU becomes impractical. Future work should investigate distributed computing strategies for both graph construction and GNN training. Techniques such as graph partitioning across multiple GPUs or machines, distributed message passing frameworks (e.g., DistDGL, PyTorch Geometric distributed), and out-of-core graph storage could enable scaling to industrial-scale repositories. Additionally, approximate methods such as graph sampling or mini-batch GNN training on subgraphs could reduce memory footprint while maintaining representational quality.}
\clipboard {text:4.14}{For extremely large bug repositories (e.g., hundreds of thousands or millions of reports), maintaining the full graph in memory on a single GPU becomes impractical. Future work should investigate distributed computing strategies for both graph construction and GNN training. Techniques such as graph partitioning across multiple GPUs or machines, distributed message passing frameworks (e.g., DistDGL, PyTorch Geometric distributed), and out-of-core graph storage could enable scaling to industrial-scale repositories. Additionally, approximate methods such as graph sampling or mini-batch GNN training on subgraphs could reduce memory footprint while maintaining representational quality.}
