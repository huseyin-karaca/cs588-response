\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{anvik}
\newlabel{sec:keywords}{{}{1}{}{Doc-Start}{}}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}\protected@file@percent }
\newlabel{sec:abstract}{{}{1}{\abstractname }{section*.2}{}}
\newlabel{rev:1.3a}{{}{1}{\abstractname }{section*.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{sun2011towards}
\citation{furnas1987vocabulary}
\citation{devlin2019bert,reimers2019sbert,lee2023sbertdupbug}
\citation{poddar2019trainone,malik2023dataaug}
\newlabel{rev:1.3b}{{1}{2}{Introduction}{section.1}{}}
\newlabel{rev:2.6}{{1}{2}{Introduction}{section.1}{}}
\newlabel{rev:3.7}{{1}{2}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Description and Motivation}{2}{section.2}\protected@file@percent }
\newlabel{sec:problem_description}{{2}{2}{Problem Description and Motivation}{section.2}{}}
\citation{sun2010discriminative}
\citation{manning2008}
\citation{salton1988,sparckjones1972}
\citation{manning2008}
\citation{furnas1987}
\citation{furnas1987}
\citation{sun2010discriminative,jalbert2008automated}
\citation{jalbert2008automated}
\citation{sun2010discriminative}
\citation{sun2010discriminative}
\citation{sun2011towards}
\citation{sun2011towards}
\citation{sun2011towards}
\citation{sun2011towards,sun2010discriminative}
\citation{sun2011towards}
\citation{chaparro2016}
\citation{he2020dualchannel}
\citation{sun2011towards}
\citation{devlin2018bert}
\citation{devlin2018bert}
\citation{liu2019roberta}
\citation{lan2020albert}
\citation{reimers2019sentencebert}
\citation{reimers2019sentencebert}
\citation{reimers2019sentencebert}
\citation{reimers2019sentencebert}
\citation{reimers2019sentencebert}
\citation{reimers2019sentencebert}
\citation{reimers2019sentencebert}
\citation{meng2024}
\newlabel{rev:3.6}{{2}{3}{Problem Description and Motivation}{section.2}{}}
\newlabel{rev:4.1}{{2}{3}{Problem Description and Motivation}{section.2}{}}
\newlabel{rev:4.2}{{2}{3}{Problem Description and Motivation}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related Work}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Information Retrieval Models}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Machine Learning Approaches}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Deep Learning for Semantic Representation}{3}{subsection.3.3}\protected@file@percent }
\citation{nguyen2012dbtm}
\citation{nguyen2012dbtm}
\citation{nguyen2012dbtm}
\citation{zhang2023cupid}
\citation{zhang2023cupid,sun2011towards}
\citation{zhang2023cupid}
\citation{zhang2023cupid}
\citation{deshmukh2017towards}
\citation{he2020dualchannel}
\citation{devlin2018bert,lan2020albert,liu2019roberta}
\citation{reimers2019sentencebert}
\citation{meng2024}
\citation{hamilton2017inductive}
\citation{hamilton2017inductive}
\citation{antoniou2017dagan}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Hybrid Systems and Emerging Approaches}{4}{subsection.3.4}\protected@file@percent }
\newlabel{sec:hybrid_emerging}{{3.4}{4}{Hybrid Systems and Emerging Approaches}{subsection.3.4}{}}
\newlabel{rev:2.2b}{{3.4}{4}{Hybrid Systems and Emerging Approaches}{table.caption.4}{}}
\newlabel{rev:1.3d}{{3.4}{4}{Hybrid Systems and Emerging Approaches}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Proposed Method}{4}{section.4}\protected@file@percent }
\newlabel{rev:1.3c}{{4}{4}{Proposed Method}{section.4}{}}
\newlabel{rev:4.8}{{4}{4}{Proposed Method}{section.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Pair Construction.}{4}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Positive pairs.}{4}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Anchor-based negative pairs.}{4}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Cross-group random negative pairs.}{4}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Final training pair sets.}{4}{section*.10}\protected@file@percent }
\citation{kipf2016semi,jiang2019semi}
\citation{koc2025graphteacher}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of Closely Related DBRD Methodologies}}{5}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:model_comparison}{{1}{5}{Comparison of Closely Related DBRD Methodologies}{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overall pipeline of the proposed method. \textbf  {Upper:} The issues are documented with issue numbers, titles, and descriptions. The positive and negative pairs are collected and stacked. Then, the token IDs are listed to be fed into BERT. \textbf  {Middle:} The graph is constructed, then BERT is employed for feature extractor and these embeddings transferred to the GNN component. Finally, the model is trained based on similarity and dissimilarities between pairs.}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:main_figure}{{1}{5}{Overall pipeline of the proposed method. \textbf {Upper:} The issues are documented with issue numbers, titles, and descriptions. The positive and negative pairs are collected and stacked. Then, the token IDs are listed to be fed into BERT. \textbf {Middle:} The graph is constructed, then BERT is employed for feature extractor and these embeddings transferred to the GNN component. Finally, the model is trained based on similarity and dissimilarities between pairs}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Embedding and Graph Construction}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Graph Construction}{5}{subsubsection.4.1.1}\protected@file@percent }
\citation{koc2025graphteacher,kocc2025scgrapht}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Embedding Construction}{6}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Training Pipeline}{6}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Fusion of Transformer and GNN representations.}{6}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Cosine embedding objective.}{6}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Validation-based decision rule.}{6}{section*.13}\protected@file@percent }
\citation{eclipse-mozilla}
\citation{devlin2019bert}
\citation{liu2019roberta}
\citation{distilbert}
\citation{codebert}
\citation{kipf2017gcn}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Inference Procedure}{7}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pairwise Inference on Test Nodes}{7}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments and Results}{7}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dataset}{7}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Statistics of the datasets used for duplicate bug report detection.}}{7}{table.caption.15}\protected@file@percent }
\newlabel{tab:datasets}{{2}{7}{Statistics of the datasets used for duplicate bug report detection}{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Experimental Setup}{7}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Evaluation Metrics}{7}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Implementation Details}{7}{subsubsection.5.2.2}\protected@file@percent }
\newlabel{rev:4.12}{{5.2.2}{7}{Implementation Details}{subsubsection.5.2.2}{}}
\newlabel{rev:1.4}{{5.2.2}{7}{Implementation Details}{subsubsection.5.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Results}{7}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Leveraging Unlabeled Data Through Graph Structure (RQ1)}{7}{subsubsection.5.3.1}\protected@file@percent }
\citation{devlin2019bert}
\citation{liu2019roberta}
\citation{distilbert}
\citation{codebert}
\citation{devlin2019bert}
\citation{liu2019roberta}
\citation{distilbert}
\citation{codebert}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Representative similarity scores on validation set pairs. Duplicate pairs consistently achieve high similarity, while non-duplicate pairs show low or negative similarity.}}{8}{table.caption.16}\protected@file@percent }
\newlabel{tab:similarity_examples}{{3}{8}{Representative similarity scores on validation set pairs. Duplicate pairs consistently achieve high similarity, while non-duplicate pairs show low or negative similarity}{table.caption.16}{}}
\@writefile{toc}{\contentsline {paragraph}{Remark:}{8}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Answer to RQ1:}{8}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Scalability of the Architecture (RQ2)}{8}{subsubsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Answer to RQ2:}{8}{section*.20}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Training time comparison on Eclipse and Thunderbird datasets. Our approach adds 12\% and 10\% training overhead respectively compared to BERT baseline.}}{8}{table.caption.19}\protected@file@percent }
\newlabel{tab:time_comparison}{{4}{8}{Training time comparison on Eclipse and Thunderbird datasets. Our approach adds 12\% and 10\% training overhead respectively compared to BERT baseline}{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Competitive Performance Evaluation (RQ3)}{8}{subsubsection.5.3.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Precision, Recall, and F1 scores on Eclipse and Thunderbird datasets. Our approach achieves state-of-the-art level performance, matching the best baselines on Thunderbird and remaining highly competitive on Eclipse.}}{8}{table.caption.21}\protected@file@percent }
\newlabel{tab:performance_results}{{5}{8}{Precision, Recall, and F1 scores on Eclipse and Thunderbird datasets. Our approach achieves state-of-the-art level performance, matching the best baselines on Thunderbird and remaining highly competitive on Eclipse}{table.caption.21}{}}
\newlabel{rev:2.4}{{5.3.3}{9}{Competitive Performance Evaluation (RQ3)}{table.caption.21}{}}
\newlabel{rev:3.8}{{5.3.3}{9}{Competitive Performance Evaluation (RQ3)}{table.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Confusion matrices visualizing classification results on both datasets. Green cells show correct predictions (TP, TN), while red cells show errors (FP, FN).}}{9}{figure.caption.22}\protected@file@percent }
\newlabel{fig:confusion_matrices}{{2}{9}{Confusion matrices visualizing classification results on both datasets. Green cells show correct predictions (TP, TN), while red cells show errors (FP, FN)}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {paragraph}{Answer to RQ3:}{9}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Training Dynamics Analysis}{9}{subsection.5.4}\protected@file@percent }
\newlabel{rev:1.1}{{5.4}{9}{Training Dynamics Analysis}{subsection.5.4}{}}
\newlabel{rev:4.11}{{5.4}{9}{Training Dynamics Analysis}{subsection.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Summary of Findings}{9}{subsection.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Training convergence on Eclipse dataset showing (left) loss curves and (right) F1 score progression over 5 epochs.}}{10}{figure.caption.23}\protected@file@percent }
\newlabel{fig:convergence_eclipse}{{3}{10}{Training convergence on Eclipse dataset showing (left) loss curves and (right) F1 score progression over 5 epochs}{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Training convergence on Thunderbird dataset showing (left) loss curves and (right) F1 score progression over 5 epochs.}}{10}{figure.caption.24}\protected@file@percent }
\newlabel{fig:convergence_thunderbird}{{4}{10}{Training convergence on Thunderbird dataset showing (left) loss curves and (right) F1 score progression over 5 epochs}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Challenges, Implications, and Future Work}{10}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Label-Scarce Validation and Inference Latency.}{11}{section*.26}\protected@file@percent }
\newlabel{rev:2.1}{{6}{11}{Label-Scarce Validation and Inference Latency}{section*.26}{}}
\newlabel{rev:2.5}{{6}{11}{Label-Scarce Validation and Inference Latency}{section*.26}{}}
\newlabel{rev:2.2a}{{6}{11}{Label-Scarce Validation and Inference Latency}{section*.26}{}}
\@writefile{toc}{\contentsline {paragraph}{Hyperparameter Sensitivity and Ablation Studies.}{11}{section*.27}\protected@file@percent }
\newlabel{rev:1.2}{{6}{11}{Hyperparameter Sensitivity and Ablation Studies}{section*.27}{}}
\newlabel{rev:2.3}{{6}{11}{Hyperparameter Sensitivity and Ablation Studies}{section*.27}{}}
\newlabel{rev:2.7}{{6}{11}{Hyperparameter Sensitivity and Ablation Studies}{section*.27}{}}
\newlabel{rev:3.2}{{6}{11}{Hyperparameter Sensitivity and Ablation Studies}{section*.27}{}}
\@writefile{toc}{\contentsline {paragraph}{Hard Negative Mining and Advanced Sampling.}{11}{section*.28}\protected@file@percent }
\newlabel{rev:3.3}{{6}{11}{Hard Negative Mining and Advanced Sampling}{section*.28}{}}
\@writefile{toc}{\contentsline {paragraph}{Incorporating Descriptions in Graph Construction.}{11}{section*.29}\protected@file@percent }
\newlabel{rev:3.1}{{6}{11}{Incorporating Descriptions in Graph Construction}{section*.29}{}}
\newlabel{rev:4.3}{{6}{11}{Incorporating Descriptions in Graph Construction}{section*.29}{}}
\@writefile{toc}{\contentsline {paragraph}{Evaluation on Diverse Datasets.}{11}{section*.30}\protected@file@percent }
\newlabel{rev:3.5}{{6}{11}{Evaluation on Diverse Datasets}{section*.30}{}}
\@writefile{toc}{\contentsline {paragraph}{Distributed Graph Construction and Storage.}{11}{section*.31}\protected@file@percent }
\newlabel{rev:3.4}{{6}{11}{Distributed Graph Construction and Storage}{section*.31}{}}
\newlabel{rev:3.9}{{6}{11}{Distributed Graph Construction and Storage}{section*.31}{}}
\newlabel{rev:4.14}{{6}{11}{Distributed Graph Construction and Storage}{section*.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Threats to Validity}{11}{subsection.6.1}\protected@file@percent }
\bibstyle{ACM-Reference-Format}
\bibdata{our-refs}
\bibcite{antoniou2017dagan}{{1}{2018}{{Antoniou et~al\mbox  {.}}}{{}}}
\bibcite{anvik}{{2}{2005}{{Anvik et~al\mbox  {.}}}{{}}}
\bibcite{chaparro2016}{{3}{2016}{{Chaparro et~al\mbox  {.}}}{{}}}
\bibcite{deshmukh2017towards}{{4}{2017}{{Deshmukh et~al\mbox  {.}}}{{}}}
\bibcite{devlin2019bert}{{5}{2019a}{{Devlin et~al\mbox  {.}}}{{}}}
\bibcite{devlin2018bert}{{6}{2019b}{{Devlin et~al\mbox  {.}}}{{}}}
\bibcite{codebert}{{7}{2020}{{Feng et~al\mbox  {.}}}{{}}}
\bibcite{furnas1987vocabulary}{{8}{1987a}{{Furnas et~al\mbox  {.}}}{{}}}
\bibcite{furnas1987}{{9}{1987b}{{Furnas et~al\mbox  {.}}}{{}}}
\bibcite{hamilton2017inductive}{{10}{2017}{{Hamilton et~al\mbox  {.}}}{{}}}
\bibcite{he2020dualchannel}{{11}{2020}{{He et~al\mbox  {.}}}{{}}}
\bibcite{jalbert2008automated}{{12}{2008}{{Jalbert and Weimer}}{{}}}
\bibcite{jiang2019semi}{{13}{2019}{{Jiang et~al\mbox  {.}}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{12}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{12}{section*.33}\protected@file@percent }
\bibcite{kipf2016semi}{{14}{2016}{{Kipf}}{{}}}
\bibcite{kipf2017gcn}{{15}{2017}{{Kipf and Welling}}{{}}}
\bibcite{koc2025graphteacher}{{16}{2025a}{{Ko{\c {c}} et~al\mbox  {.}}}{{}}}
\bibcite{kocc2025scgrapht}{{17}{2025b}{{Ko{\c {c}} et~al\mbox  {.}}}{{}}}
\bibcite{eclipse-mozilla}{{18}{2013}{{Lamkanfi et~al\mbox  {.}}}{{}}}
\bibcite{lan2020albert}{{19}{2020}{{Lan et~al\mbox  {.}}}{{}}}
\bibcite{lee2023sbertdupbug}{{20}{2023}{{Lee}}{{}}}
\bibcite{liu2019roberta}{{21}{2019}{{Liu et~al\mbox  {.}}}{{}}}
\bibcite{malik2023dataaug}{{22}{2023}{{Malik et~al\mbox  {.}}}{{}}}
\bibcite{manning2008}{{23}{2008}{{Manning et~al\mbox  {.}}}{{}}}
\bibcite{meng2024}{{24}{2024}{{Meng et~al\mbox  {.}}}{{}}}
\bibcite{nguyen2012dbtm}{{25}{2012}{{Nguyen et~al\mbox  {.}}}{{}}}
\bibcite{poddar2019trainone}{{26}{2019}{{Poddar et~al\mbox  {.}}}{{}}}
\bibcite{reimers2019sbert}{{27}{2019a}{{Reimers and Gurevych}}{{}}}
\bibcite{reimers2019sentencebert}{{28}{2019b}{{Reimers and Gurevych}}{{}}}
\bibcite{salton1988}{{29}{1988}{{Salton and Buckley}}{{}}}
\bibcite{distilbert}{{30}{2020}{{Sanh et~al\mbox  {.}}}{{}}}
\bibcite{sparckjones1972}{{31}{1972}{{Sparck~Jones}}{{}}}
\bibcite{sun2011towards}{{32}{2011}{{Sun et~al\mbox  {.}}}{{}}}
\bibcite{sun2010discriminative}{{33}{2010}{{Sun et~al\mbox  {.}}}{{}}}
\bibcite{zhang2023cupid}{{34}{2023}{{Zhang et~al\mbox  {.}}}{{}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.185pt}
\newlabel{tocindent2}{10.34999pt}
\newlabel{tocindent3}{18.198pt}
\newlabel{TotPages}{{13}{13}{}{page.13}{}}
\gdef \@abspage@last{13}
